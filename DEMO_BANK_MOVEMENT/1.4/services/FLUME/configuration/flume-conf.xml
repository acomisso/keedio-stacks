<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->

<configuration supports_final="false">
  <property>
    <name>content</name>
    <description>Flume agent configurations. 
    Specifying the configuration here applies to all hosts in this configuration-group. Please use host specific configuration-groups to provide different configurations on different hosts. 
    For configuring multiple agents on the same host, provide the combined agent configurations here. Each agent should have a different name.</description>
    <value>
#Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources,
# the channels and the sinks.
# Sources, channels and sinks are defined per agent,
# in this case called 'agent'

agent.sources = syslog
agent.channels = memoryChannel
agent.sinks = kafka-sink hdfsSink
#agent.sinks = loggerSink

# For each one of the sources, the type is defined
agent.sources.syslog.type = syslogudp
agent.sources.syslog.host = 0.0.0.0
agent.sources.syslog.port = 5140

# The channel can be defined as follows.
agent.sources.syslog.channels = memoryChannel

agent.sources.syslog.interceptors = i0 i2 i3

# interceptor

agent.sources.syslog.interceptors.i0.type = org.keedio.flume.interceptor.enrichment.interceptor.EnrichmentInterceptor$EnrichmentBuilder
# Full path to the properties file that contains the extra data to enrich the event with
#agent.sources.syslog.interceptors.i0.properties.filename = /Users/luca/projects/keedio/vectordemo/vector.properties
# The format of incoming events ( DEFAULT | enriched )
agent.sources.syslog.interceptors.i0.event.type = DEFAULT
agent.sources.syslog.interceptors.i0.custom.regexp.1 = AccountTransaction\\(.*,(?&lt;srcCountry&gt;.{2}),(?&lt;srcCity&gt;[^,]+),(?&lt;srcRegion&gt;.{2}),(?&lt;destCountry&gt;.{2}),(?&lt;destCity&gt;[^,]+),(?&lt;destRegion&gt;.{2})\\)$

agent.sources.syslog.interceptors.i1.dump.filename = /tmp/myflume-integrationtest.dmp
agent.sources.syslog.interceptors.i1.type = org.keedio.flume.interceptor.FileDumpInterceptorBuilder
agent.sources.syslog.interceptors.i1.dump.maxFileSize = 10MB
agent.sources.syslog.interceptors.i1.dump.maxBackups = 10

agent.sources.syslog.interceptors.i2.type = org.keedio.flume.interceptor.cacheable.interceptor.CacheableInterceptor$Builder

# Cache eviction
# interval is expressed in seconds, default to 10 seconds
agent.sources.syslog.interceptors.i2.properties.lock.filename = /opt/keedio-examples/bankmovements-demo/flume-cache1.lock
agent.sources.syslog.interceptors.i2.properties.lock.interval = 3600

# Data insertion
# CSV separator defaults to comma ","
agent.sources.syslog.interceptors.i2.properties.csv.directory = /opt/keedio-examples/bankmovements-demo/csv1
agent.sources.syslog.interceptors.i2.properties.csv.separator = ,
agent.sources.syslog.interceptors.i2.properties.csv.quote.char = |

agent.sources.syslog.interceptors.i3.type = org.keedio.flume.interceptor.cacheable.interceptor.CacheableInterceptor$Builder

# Cache eviction
# interval is expressed in seconds, default to 10 seconds
agent.sources.syslog.interceptors.i3.properties.lock.filename = /opt/keedio-examples/bankmovements-demo/flume-cache2.lock
agent.sources.syslog.interceptors.i3.properties.lock.interval = 3600

# Data insertion
# CSV separator defaults to comma ","
agent.sources.syslog.interceptors.i3.properties.csv.directory = /opt/keedio-examples/bankmovements-demo/csv2
agent.sources.syslog.interceptors.i3.properties.csv.separator = ,
agent.sources.syslog.interceptors.i3.properties.csv.quote.char = |

# Each sink's type must be defined
agent.sinks.loggerSink.type = logger

#Specify the channel the sink should use
agent.sinks.loggerSink.channel = memoryChannel

# In async producer:
agent.sinks.kafka-sink.channel = memoryChannel
agent.sinks.kafka-sink.type = org.keedio.flume.sink.KafkaSink
agent.sinks.kafka-sink.zk.connect = keedio11:2181,keedio12:2181,keedio13:2181
agent.sinks.kafka-sink.defaultTopic = flume
#agent.sinks.kafka-sink.dynamicTopic = hostname-item
agent.sinks.kafka-sink.batch.num.messages = 1000
agent.sinks.kafka-sink.queue.buffering.max.ms = 1000
agent.sinks.kafka-sink.producer.type = async
agent.sinks.kafka-sink.metadata.broker.list = keedio11:9092,keedio12:9092,keedio13:9092

agent.sinks.hdfsSink.type = hdfs
agent.sinks.hdfsSink.hdfs.path = /user/flume/syslogdump
agent.sinks.hdfsSink.channel = memoryChannel
agent.sinks.hdfsSink.hdfs.filePrefix = %{host}_%Y%m%d_%H
agent.sinks.hdfsSink.hdfs.rollInterval = 0
agent.sinks.hdfsSink.hdfs.writeFormat = Text
agent.sinks.hdfsSink.hdfs.batchSize = 100
# 10k
agent.sinks.hdfsSink.hdfs.rollSize = 67108864
#agent.sinks.hdfsSink.hdfs.codeC = gzip
agent.sinks.hdfsSink.hdfs.rollCount = 0

# Each channel's type is defined.
agent.channels.memoryChannel.type = memory

# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
agent.channels.memoryChannel.capacity = 10000
    </value>
  </property>
</configuration>
