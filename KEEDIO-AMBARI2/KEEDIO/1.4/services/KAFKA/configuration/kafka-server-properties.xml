<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->

<configuration>
  <property>
    <name>port</name>
    <value>9092</value>
    <description>The port the socket server listens on</description>
  </property>

  <property>
    <name>num.network.threads</name>
    <value>2</value>
    <description>Number of threads handling network requests</description>
  </property>

  <property>
    <name>num.io.threads</name>
    <value>8</value>
    <description>Number of threads handling IO requests</description>
  </property>

  <property>
    <name>socket.send.buffer.bytes</name>
    <value>102400</value>
    <description>The send buffer (SO:SNDBUF) used by socket server</description>
  </property>

  <property>
    <name>socket.receive.buffer.bytes</name>
    <value>102400</value>
    <description>The receive buffer (SO_RCVBUF) used by socket server</description>
  </property>

  <property>
    <name>socket.request.max.bytes</name>
    <value>104857600</value>
    <description>The maximum size of a request that the socket server will accept (rotection against OOM)</description>
  </property>

  <property>
    <name>log.dirs</name>
    <value>/var/lib/kafka</value>
    <description>Directory under which store topics files</description>
  </property>

  <property>
    <name>num.partitions</name>
    <value>2</value>
    <description>The default number of log partitions per topic. More partitions allow greater parallelism for consumtion, but this will also result in more files across brokers</description>
  </property>

  <property>
    <name>log.flush.interval.messages</name>
    <value>10000</value>
    <description>The number of messages to accept before forcing a flush of data to disk</description>
  </property>

  <property>
    <name>log.flush.interval.ms</name>
    <value>1000</value>
    <description>The maximum amount of time a message can sit in a log before we force a flush</description>
  </property>

  <property>
    <name>log.retention.hours</name>
    <value>168</value>
    <description>The minimum age of a log file to be elegible for deletion</description>
  </property>

  <property>
    <name>log.segment.bytes</name>
    <value>536870912</value>
    <description>The maximum size of a log segment file. When this size is reached a new log segment will be created</description>
  </property>

  <property>
    <name>log.retention.check.interval.ms</name>
    <value>60000</value>
    <description>The interval at which log segments are checked to see if they can be deleted according to the retention policies</description>
  </property>

  <property>
    <name>log.cleaner.enable</name>
    <value>false</value>
    <description>By default the log cleaner is disabled and the log retention policy will default to just delete segments after their retention expires. If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction
    </description>
  </property>

  <property>
    <name>zookeeper.connect</name>
    <value>localhost:2181/kafka</value>
    <description>Zookeeper connection string</description>
  </property>

  <property>
    <name>zookeeper.connection.timeout.ms</name>
    <value>1000000</value>
    <description>Timeout in ms for connection to zookeeper</description>
  </property>

  <property>
    <name>log.roll.hours</name>
    <value>168</value>
    <description>
      This setting will force Kafka to roll a new log segment even if the log.segment.bytes size has not been reached.
    </description>
  </property>
 

</configuration> 
